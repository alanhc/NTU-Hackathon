{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T22:32:20.283433Z",
     "start_time": "2019-03-30T22:31:58.649491Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: (280, 192, 256, 3)\n",
      "Train Label:  (280, 4)\n",
      "Test Data:  (120, 192, 256, 3)\n",
      "Test Label:  (120, 4)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 191, 255, 16)      208       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 191, 255, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 95, 127, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 93, 125, 32)       4640      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 93, 125, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 46, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 44, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 44, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 261,732\n",
      "Trainable params: 261,732\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 280 samples, validate on 120 samples\n",
      "Epoch 1/20\n",
      "280/280 [==============================] - 4s 16ms/step - loss: 8.7568 - acc: 0.3500 - val_loss: 4.9157 - val_acc: 0.4500\n",
      "Epoch 2/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.9119 - acc: 0.4393 - val_loss: 0.8958 - val_acc: 0.6417\n",
      "Epoch 3/20\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 1.8201 - acc: 0.5679 - val_loss: 0.8394 - val_acc: 0.7250\n",
      "Epoch 4/20\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 1.2368 - acc: 0.6000 - val_loss: 0.7386 - val_acc: 0.5917\n",
      "Epoch 5/20\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.7773 - acc: 0.7393 - val_loss: 0.7039 - val_acc: 0.6250\n",
      "Epoch 6/20\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.5697 - acc: 0.7893 - val_loss: 0.6876 - val_acc: 0.6000\n",
      "Epoch 7/20\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.4041 - acc: 0.8179 - val_loss: 0.5944 - val_acc: 0.7083\n",
      "Epoch 8/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.4015 - acc: 0.8036 - val_loss: 0.6072 - val_acc: 0.8250\n",
      "Epoch 9/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.3290 - acc: 0.8643 - val_loss: 0.5815 - val_acc: 0.8250\n",
      "Epoch 10/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.3641 - acc: 0.8357 - val_loss: 0.5660 - val_acc: 0.8417\n",
      "Epoch 11/20\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.2421 - acc: 0.9071 - val_loss: 0.6204 - val_acc: 0.8417\n",
      "Epoch 12/20\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.2476 - acc: 0.8929 - val_loss: 0.6194 - val_acc: 0.8417\n",
      "Epoch 13/20\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.2408 - acc: 0.9214 - val_loss: 0.5541 - val_acc: 0.8417\n",
      "Epoch 14/20\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.2116 - acc: 0.9214 - val_loss: 0.6945 - val_acc: 0.8333\n",
      "Epoch 15/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1744 - acc: 0.9393 - val_loss: 0.9286 - val_acc: 0.8250\n",
      "Epoch 16/20\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 0.1703 - acc: 0.9393 - val_loss: 1.1109 - val_acc: 0.8250\n",
      "Epoch 17/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1401 - acc: 0.9357 - val_loss: 1.0757 - val_acc: 0.8250\n",
      "Epoch 18/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1640 - acc: 0.9357 - val_loss: 0.9918 - val_acc: 0.7667\n",
      "Epoch 19/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1276 - acc: 0.9464 - val_loss: 0.9223 - val_acc: 0.8250\n",
      "Epoch 20/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.1040 - acc: 0.9643 - val_loss: 1.0267 - val_acc: 0.8167\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "Loss: 1.027, Accuracy: 0.817\n",
      "Finish training!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, AveragePooling1D, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import load_model\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "trainD = np.load(\"stevensTrainingData/trainingData.npy\")\n",
    "trainL = np.load(\"stevensTrainingData/trainingLabel.npy\")\n",
    "testD = np.load(\"stevensTrainingData/testingData.npy\")\n",
    "testL = np.load(\"stevensTrainingData/testingLabel.npy\")\n",
    "\n",
    "\n",
    "trainData = trainD / 255\n",
    "testData = testD / 255\n",
    "\n",
    "\n",
    "trainData_normalize = trainD.reshape(trainData.shape[0], trainData.shape[1], trainData.shape[2], 3).astype('uint8')\n",
    "trainLabel_onehot = np_utils.to_categorical(trainL, 4)\n",
    "testData_normalize = testD.reshape(testData.shape[0], testData.shape[1], testData.shape[2], 3).astype('uint8')\n",
    "testLabel_onehot = np_utils.to_categorical(testL, 4)\n",
    "print('Train Data:', trainData_normalize.shape)\n",
    "print('Train Label: ', trainLabel_onehot.shape)\n",
    "print('Test Data: ', testData_normalize.shape)\n",
    "print('Test Label: ', testLabel_onehot.shape)\n",
    "\n",
    "#建立CNN模型\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = (2, 2), input_shape = (trainData_normalize.shape[1], trainData_normalize.shape[2], 3), data_format = \"channels_last\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), data_format = \"channels_last\"))\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), data_format = \"channels_last\"))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (3, 3), data_format = \"channels_last\"))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (3, 3), data_format = \"channels_last\"))\n",
    "\n",
    "#建立分類模型\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(4, activation = \"softmax\"))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "adam = Adam(lr = 0.001)\n",
    "model.compile(optimizer = adam, loss = \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(patience=20)\n",
    "\n",
    "train_history_1 = model.fit(x = trainData_normalize,\n",
    "                            y = trainLabel_onehot,\n",
    "                            epochs=20,\n",
    "                            validation_data=(testData_normalize, testLabel_onehot),\n",
    "                            batch_size=100, \n",
    "                            verbose=1\n",
    "                           )\n",
    "\n",
    "evaluation = model.evaluate(x = testData_normalize, y = testLabel_onehot)\n",
    "print('Loss: {:.3f}, Accuracy: {:.3f}'.format(evaluation[0], evaluation[1]))\n",
    "\n",
    "\n",
    "model.save(\"human_detection_model.h5\")\n",
    "\n",
    "print('Finish training!')\n",
    "\n",
    "import pylab as plt\n",
    "def history_display(hist, train, validation):\n",
    "    plt.plot(hist.history[train])\n",
    "    plt.plot(hist.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show\n",
    "    \n",
    "def show_plot(flag, hist):\n",
    "    if flag == 'acc':\n",
    "        history_display(hist, 'acc', 'val_acc')\n",
    "    elif flag == 'loss':\n",
    "        history_display(hist, 'loss', 'val_loss')\n",
    "    else:\n",
    "        print('Invalid!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T16:23:23.940076Z",
     "start_time": "2019-03-30T16:23:19.523301Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, AveragePooling1D, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('human_detection_model_0875.h5')\n",
    "imagenpy = np.load(\"sampleImage.npy\")\n",
    "imagenpy = imagenpy.reshape((1, imagenpy.shape[0], imagenpy.shape[1], imagenpy.shape[2]))\n",
    "result = model.predict(imagenpy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T16:23:27.492872Z",
     "start_time": "2019-03-30T16:23:27.486985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12593701 0.04073597 0.41777843 0.41554862]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
