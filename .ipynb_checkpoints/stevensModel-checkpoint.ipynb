{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T15:39:04.812330Z",
     "start_time": "2019-03-30T15:38:46.750336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: (280, 192, 256, 3)\n",
      "Train Label:  (280, 4)\n",
      "Test Data:  (120, 192, 256, 3)\n",
      "Test Label:  (120, 4)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 191, 255, 16)      208       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 191, 255, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 95, 127, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 93, 125, 32)       4640      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 93, 125, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 46, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 44, 60, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 44, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 14, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 12, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 12, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 4, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 261,732\n",
      "Trainable params: 261,732\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 280 samples, validate on 120 samples\n",
      "Epoch 1/20\n",
      "280/280 [==============================] - 2s 6ms/step - loss: 11.4320 - acc: 0.2214 - val_loss: 12.0886 - val_acc: 0.2500\n",
      "Epoch 2/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 10.8238 - acc: 0.2393 - val_loss: 8.5807 - val_acc: 0.2500\n",
      "Epoch 3/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 7.4907 - acc: 0.2929 - val_loss: 3.2870 - val_acc: 0.2500\n",
      "Epoch 4/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 4.7028 - acc: 0.3071 - val_loss: 2.1267 - val_acc: 0.2500\n",
      "Epoch 5/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 2.3593 - acc: 0.2607 - val_loss: 1.4255 - val_acc: 0.2500\n",
      "Epoch 6/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.8482 - acc: 0.2464 - val_loss: 1.3967 - val_acc: 0.3500\n",
      "Epoch 7/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.4672 - acc: 0.3000 - val_loss: 1.3634 - val_acc: 0.4167\n",
      "Epoch 8/20\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 1.4271 - acc: 0.2964 - val_loss: 1.3714 - val_acc: 0.4333\n",
      "Epoch 9/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.3654 - acc: 0.3250 - val_loss: 1.3979 - val_acc: 0.2833\n",
      "Epoch 10/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.3565 - acc: 0.3571 - val_loss: 1.3688 - val_acc: 0.1000\n",
      "Epoch 11/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.3050 - acc: 0.4286 - val_loss: 1.2901 - val_acc: 0.5583\n",
      "Epoch 12/20\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 1.2515 - acc: 0.4143 - val_loss: 1.2280 - val_acc: 0.5000\n",
      "Epoch 13/20\n",
      "280/280 [==============================] - 1s 2ms/step - loss: 1.1671 - acc: 0.5357 - val_loss: 1.1737 - val_acc: 0.4667\n",
      "Epoch 14/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 1.1095 - acc: 0.5750 - val_loss: 1.0617 - val_acc: 0.7417\n",
      "Epoch 15/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.9718 - acc: 0.6286 - val_loss: 0.9963 - val_acc: 0.6667\n",
      "Epoch 16/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.8614 - acc: 0.6786 - val_loss: 0.8156 - val_acc: 0.7500\n",
      "Epoch 17/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.7241 - acc: 0.7750 - val_loss: 0.6693 - val_acc: 0.7500\n",
      "Epoch 18/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.6030 - acc: 0.8107 - val_loss: 0.5943 - val_acc: 0.7500\n",
      "Epoch 19/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.5329 - acc: 0.8286 - val_loss: 0.4667 - val_acc: 0.7500\n",
      "Epoch 20/20\n",
      "280/280 [==============================] - 1s 3ms/step - loss: 0.4491 - acc: 0.8750 - val_loss: 0.3638 - val_acc: 0.9250\n",
      "120/120 [==============================] - 0s 1ms/step\n",
      "Loss: 0.364, Accuracy: 0.925\n",
      "Finish training!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, AveragePooling1D, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import load_model\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "trainD = np.load(\"stevensTrainingData/trainingData.npy\")\n",
    "trainL = np.load(\"stevensTrainingData/trainingLabel.npy\")\n",
    "testD = np.load(\"stevensTrainingData/testingData.npy\")\n",
    "testL = np.load(\"stevensTrainingData/testingLabel.npy\")\n",
    "\n",
    "\n",
    "trainData = trainD / 255\n",
    "testData = testD / 255\n",
    "\n",
    "\n",
    "trainData_normalize = trainD.reshape(trainData.shape[0], trainData.shape[1], trainData.shape[2], 3).astype('uint8')\n",
    "trainLabel_onehot = np_utils.to_categorical(trainL, 4)\n",
    "testData_normalize = testD.reshape(testData.shape[0], testData.shape[1], testData.shape[2], 3).astype('uint8')\n",
    "testLabel_onehot = np_utils.to_categorical(testL, 4)\n",
    "print('Train Data:', trainData_normalize.shape)\n",
    "print('Train Label: ', trainLabel_onehot.shape)\n",
    "print('Test Data: ', testData_normalize.shape)\n",
    "print('Test Label: ', testLabel_onehot.shape)\n",
    "\n",
    "#建立CNN模型\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = (2, 2), input_shape = (trainData_normalize.shape[1], trainData_normalize.shape[2], 3), data_format = \"channels_last\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), data_format = \"channels_last\"))\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), data_format = \"channels_last\"))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (3, 3), data_format = \"channels_last\"))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (3, 3), data_format = \"channels_last\"))\n",
    "\n",
    "#建立分類模型\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(4, activation = \"softmax\"))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "adam = Adam(lr = 0.001)\n",
    "model.compile(optimizer = adam, loss = \"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(patience=20)\n",
    "\n",
    "train_history_1 = model.fit(x = trainData_normalize,\n",
    "                            y = trainLabel_onehot,\n",
    "                            epochs=20,\n",
    "                            validation_data=(testData_normalize, testLabel_onehot),\n",
    "                            batch_size=100, \n",
    "                            verbose=1\n",
    "                           )\n",
    "\n",
    "evaluation = model.evaluate(x = testData_normalize, y = testLabel_onehot)\n",
    "print('Loss: {:.3f}, Accuracy: {:.3f}'.format(evaluation[0], evaluation[1]))\n",
    "\n",
    "\n",
    "model.save(\"human_detection_model.h5\")\n",
    "\n",
    "print('Finish training!')\n",
    "\n",
    "import pylab as plt\n",
    "def history_display(hist, train, validation):\n",
    "    plt.plot(hist.history[train])\n",
    "    plt.plot(hist.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show\n",
    "    \n",
    "def show_plot(flag, hist):\n",
    "    if flag == 'acc':\n",
    "        history_display(hist, 'acc', 'val_acc')\n",
    "    elif flag == 'loss':\n",
    "        history_display(hist, 'loss', 'val_loss')\n",
    "    else:\n",
    "        print('Invalid!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-30T16:20:14.801966Z",
     "start_time": "2019-03-30T16:20:09.595271Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, AveragePooling1D, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('human_detection_model_0875.h5')\n",
    "imagenpy = np.load(\"sampleImage.npy\")\n",
    "imagenpy = imagenpy.reshape((1, imagenpy.shape[0], imagenpy.shape[1], imagenpy.shape[2]))\n",
    "result = model.predict(imagenpy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
